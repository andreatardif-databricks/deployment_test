{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notification Webhook\n",
        "\n",
        "Reads job run outcome via Databricks SDK and sends styled HTML email (success/failure)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Widgets: optional values from upstream task\n",
        "dbutils.widgets.text(\"received_message\", \"\", \"From run_pipeline\")\n",
        "dbutils.widgets.text(\"job_id\", \"\", \"Job ID\")\n",
        "dbutils.widgets.text(\"run_id\", \"\", \"Run ID\")\n",
        "\n",
        "dbutils.widgets.text(\"job_status\", \"\")\n",
        "job_status = dbutils.widgets.get(\"job_status\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import smtplib\n",
        "from datetime import datetime\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "from databricks.sdk import WorkspaceClient\n",
        "from databricks.sdk.service.jobs import RunResultState\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "HTML_EMAIL_TEMPLATE = \"\"\"\n",
        "<html>\n",
        "  <head>\n",
        "    <style>\n",
        "      body {{ font-family: Arial, sans-serif; margin: 0; padding: 0; background-color: #f4f4f4; color: #333333; }}\n",
        "      .email-container {{ width: 95%; margin: auto; background-color: #ffffff; border-radius: 6px; padding: 10px 20px; box-shadow: 0 2px 8px rgba(0,0,0,0.05); }}\n",
        "      .alert-box {{ background-color: #0099D8; color: white; padding: 16px; text-align: center; font-size: 16px; font-weight: bold; border-radius: 4px; margin-bottom: 20px; }}\n",
        "      .alert-box.failed {{ background-color: #c0392b; }}\n",
        "      .content pre {{ white-space: pre-wrap; font-family: inherit; font-size: 13px; }}\n",
        "      .footer {{ padding: 16px 0; font-size: 12px; color: #777777; text-align: center; }}\n",
        "    </style>\n",
        "  </head>\n",
        "  <body>\n",
        "    <div class=\"email-container\">\n",
        "      <div class=\"alert-box {alert_class}\">{alert_message}</div>\n",
        "      <div class=\"content\">{content}</div>\n",
        "      <div class=\"footer\">Sent via Databricks pipeline • {timestamp}</div>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "def _build_html_body(alert_message, content_html, alert_class=\"\"):\n",
        "    now = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "    return HTML_EMAIL_TEMPLATE.format(alert_message=alert_message, content=content_html, alert_class=alert_class, timestamp=now)\n",
        "\n",
        "def _get_spark_conf(key, default=\"\"):\n",
        "    try:\n",
        "        return spark.conf.get(key, default)\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "# Secret scope containing SMTP_HOST, SMTP_PORT, SMTP_PASSWORD (override via env if different)\n",
        "SMTP_HOST = dbutils.secrets.get(scope=\"andrea_tardif_smtp_scope\", key=\"SMTP_HOST\")\n",
        "SMTP_PORT = int(dbutils.secrets.get(scope=\"andrea_tardif_smtp_scope\", key=\"SMTP_PORT\"))\n",
        "SMTP_PASSWORD = dbutils.secrets.get(scope=\"andrea_tardif_smtp_scope\", key=\"SMTP_PASSWORD\")\n",
        "\n",
        "SMTP_USER = os.environ.get(\"SMTP_USER\", \"andrea.tardif16@gmail.com\")\n",
        "ALERT_TO = os.environ.get(\"ALERT_RECIPIENT\", \"andrea.tardif@databricks.com\")\n",
        "CATALOG = os.environ.get(\"CATALOG\", \"andrea_tardif\")\n",
        "\n",
        "WORKSPACE_URL = _get_spark_conf(\"spark.databricks.workspaceUrl\", \"\")\n",
        "\n",
        "JOB_ID = dbutils.widgets.get(\"job_id\") or _get_spark_conf(\"spark.databricks.job.id\", \"\")\n",
        "RUN_ID = dbutils.widgets.get(\"run_id\") or _get_spark_conf(\"spark.databricks.job.runId\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _parse_job_ids():\n",
        "    try:\n",
        "        if not RUN_ID or not str(RUN_ID).strip() or not JOB_ID or not str(JOB_ID).strip():\n",
        "            return None, None\n",
        "        r, j = int(str(RUN_ID).strip()), int(str(JOB_ID).strip())\n",
        "        if r < 1 or j < 1:\n",
        "            return None, None\n",
        "        return r, j\n",
        "    except (ValueError, TypeError):\n",
        "        return None, None\n",
        "\n",
        "_run_id, _job_id = _parse_job_ids()\n",
        "run, job = None, None\n",
        "if _run_id is None or _job_id is None:\n",
        "    print(\"[NOTIFY] Not running in a Databricks job (runId/id not available or invalid) — skipping notification.\")\n",
        "else:\n",
        "    try:\n",
        "        client = WorkspaceClient()\n",
        "        run = client.jobs.get_run(run_id=_run_id)\n",
        "        job = client.jobs.get(job_id=_job_id)\n",
        "    except Exception as e:\n",
        "        print(f\"[NOTIFY] Could not fetch run/job from API: {e} — skipping notification.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Send failure email based on job_status (this notebook runs only on failure path)\n",
        "job_name = job.settings.name if job is not None else f\"Job {JOB_ID}\"\n",
        "run_url = f\"{WORKSPACE_URL}#job/{JOB_ID}/run/{RUN_ID}\"\n",
        "state_message = (run.state.state_message or \"\") if run is not None else \"Pipeline task failed or did not set status.\"\n",
        "task_summaries = []\n",
        "if run is not None and run.tasks:\n",
        "    for task in run.tasks:\n",
        "        task_summaries.append(f\"  • {task.task_key}: {task.state.result_state} \" +\n",
        "            (f\"(error: {task.state.state_message})\" if task.state.state_message else \"(ok)\"))\n",
        "task_summary_text = \"\\n\".join(task_summaries) if task_summaries else \"  (no task details)\"\n",
        "\n",
        "now = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S UTC\")\n",
        "subject = f\"❌ [{job_name}] Run {RUN_ID} — FAILED\"\n",
        "alert_message = \"Pipeline run failed.\"\n",
        "alert_class = \"failed\"\n",
        "content_html = f\"<p><strong>Job:</strong> {job_name}<br><strong>Run ID:</strong> {RUN_ID}<br><a href=\\\"{run_url}\\\">Open run</a></p><p><strong>Error</strong></p><pre>{state_message or 'N/A'}</pre><p><strong>Tasks</strong></p><pre>{task_summary_text}</pre>\"\n",
        "body = _build_html_body(alert_message, content_html, alert_class)\n",
        "if ALERT_TO:\n",
        "    msg = MIMEMultipart(\"alternative\")\n",
        "    msg[\"From\"] = SMTP_USER\n",
        "    msg[\"To\"] = ALERT_TO\n",
        "    msg[\"Subject\"] = subject\n",
        "    msg.attach(MIMEText(body, \"html\"))\n",
        "    try:\n",
        "        with smtplib.SMTP(SMTP_HOST, SMTP_PORT) as server:\n",
        "            server.ehlo()\n",
        "            server.starttls()\n",
        "            server.login(SMTP_USER, SMTP_PASSWORD)\n",
        "            server.send_message(msg)\n",
        "            server.quit()\n",
        "        print(f\"✅ Email sent to {ALERT_TO}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to send email: {e}\")\n",
        "else:\n",
        "    print(\"[NOTIFY] ALERT_RECIPIENT not set — skipping email.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
