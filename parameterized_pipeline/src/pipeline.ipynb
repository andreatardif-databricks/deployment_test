{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parameterized DLT Pipeline\n",
        "\n",
        "This pipeline uses configuration parameters passed from the DABs bundle to avoid duplicating pipeline definitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dlt\n",
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Configuration Parameters\n",
        "\n",
        "These parameters are passed from the pipeline configuration in the DABs bundle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get configuration from pipeline settings\n",
        "catalog = spark.conf.get(\"catalog\", \"main\")\n",
        "schema = spark.conf.get(\"schema\", \"default\")\n",
        "source_table = spark.conf.get(\"source_table\", \"raw_data\")\n",
        "target_table = spark.conf.get(\"target_table\", \"processed_data\")\n",
        "pipeline_config = spark.conf.get(\"pipeline_config\", \"dev\")\n",
        "\n",
        "print(f\"Pipeline Configuration: {pipeline_config}\")\n",
        "print(f\"Catalog: {catalog}\")\n",
        "print(f\"Schema: {schema}\")\n",
        "print(f\"Source Table: {source_table}\")\n",
        "print(f\"Target Table: {target_table}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bronze Layer - Raw Data Ingestion\n",
        "\n",
        "This table ingests raw data. In this example, we'll create sample data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dlt.table(\n",
        "    name=\"raw_data\",\n",
        "    comment=\"Raw data ingestion layer\",\n",
        "    table_properties={\n",
        "        \"quality\": \"bronze\",\n",
        "        \"pipeline_config\": pipeline_config\n",
        "    }\n",
        ")\n",
        "def bronze_raw_data():\n",
        "    \"\"\"Ingest raw data - in this example we create sample data\"\"\"\n",
        "    return (\n",
        "        spark.range(0, 100)\n",
        "        .withColumn(\"name\", F.concat(F.lit(\"user_\"), F.col(\"id\")))\n",
        "        .withColumn(\"value\", F.rand() * 100)\n",
        "        .withColumn(\"timestamp\", F.current_timestamp())\n",
        "        .withColumn(\"config\", F.lit(pipeline_config))\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Silver Layer - Data Cleansing and Transformation\n",
        "\n",
        "This table applies data quality checks and transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dlt.table(\n",
        "    name=\"processed_data\",\n",
        "    comment=\"Processed data with quality checks\",\n",
        "    table_properties={\n",
        "        \"quality\": \"silver\",\n",
        "        \"pipeline_config\": pipeline_config\n",
        "    }\n",
        ")\n",
        "@dlt.expect_or_drop(\"valid_id\", \"id IS NOT NULL\")\n",
        "@dlt.expect_or_drop(\"valid_value\", \"value >= 0\")\n",
        "def silver_processed_data():\n",
        "    \"\"\"Apply data quality checks and transformations\"\"\"\n",
        "    return (\n",
        "        dlt.read(\"raw_data\")\n",
        "        .withColumn(\"value_rounded\", F.round(F.col(\"value\"), 2))\n",
        "        .withColumn(\"value_category\", \n",
        "            F.when(F.col(\"value\") < 33, \"low\")\n",
        "            .when(F.col(\"value\") < 66, \"medium\")\n",
        "            .otherwise(\"high\")\n",
        "        )\n",
        "        .withColumn(\"processed_timestamp\", F.current_timestamp())\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gold Layer - Aggregated Data\n",
        "\n",
        "This table creates business-ready aggregated data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dlt.table(\n",
        "    name=\"aggregated_data\",\n",
        "    comment=\"Aggregated business-ready data\",\n",
        "    table_properties={\n",
        "        \"quality\": \"gold\",\n",
        "        \"pipeline_config\": pipeline_config\n",
        "    }\n",
        ")\n",
        "def gold_aggregated_data():\n",
        "    \"\"\"Create aggregated metrics\"\"\"\n",
        "    return (\n",
        "        dlt.read(\"processed_data\")\n",
        "        .groupBy(\"value_category\", \"config\")\n",
        "        .agg(\n",
        "            F.count(\"*\").alias(\"record_count\"),\n",
        "            F.avg(\"value_rounded\").alias(\"avg_value\"),\n",
        "            F.min(\"value_rounded\").alias(\"min_value\"),\n",
        "            F.max(\"value_rounded\").alias(\"max_value\"),\n",
        "            F.stddev(\"value_rounded\").alias(\"stddev_value\")\n",
        "        )\n",
        "        .withColumn(\"aggregation_timestamp\", F.current_timestamp())\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
